#!/usr/bin/env python3
"""
GPUé©±åŠ¨æµ‹è¯•ç¨‹åº
ç”¨äºéªŒè¯NVIDIAé©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…å’Œé…ç½®
"""

import sys
import subprocess
import time

def check_nvidia_smi():
    """æ£€æŸ¥nvidia-smiå‘½ä»¤æ˜¯å¦å¯ç”¨"""
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ“ nvidia-smi å‘½ä»¤å¯ç”¨")
            print("GPUä¿¡æ¯:")
            print(result.stdout)
            return True
        else:
            print("âœ— nvidia-smi å‘½ä»¤å¤±è´¥:")
            print(result.stderr)
            return False
    except FileNotFoundError:
        print("âœ— nvidia-smi å‘½ä»¤æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥NVIDIAé©±åŠ¨å®‰è£…")
        return False

def test_cuda_basic():
    """æµ‹è¯•åŸºæœ¬çš„CUDAåŠŸèƒ½"""
    try:
        import torch
        print(f"âœ“ PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        if torch.cuda.is_available():
            print(f"âœ“ CUDAå¯ç”¨ï¼Œè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"  - GPU {i}: {torch.cuda.get_device_name(i)}")
                print(f"    å†…å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")
            
            # ç®€å•çš„GPUè®¡ç®—æµ‹è¯•
            device = torch.cuda.current_device()
            print(f"\nâœ“ å½“å‰ä½¿ç”¨GPU: {device}")
            
            # åˆ›å»ºæµ‹è¯•å¼ é‡
            x = torch.rand(1000, 1000).cuda()
            y = torch.rand(1000, 1000).cuda()
            
            start_time = time.time()
            z = torch.matmul(x, y)
            print(z)
            torch.cuda.synchronize()  # ç­‰å¾…GPUå®Œæˆè®¡ç®—
            end_time = time.time()
            
            print(f"âœ“ GPUçŸ©é˜µä¹˜æ³•æµ‹è¯•å®Œæˆ")
            print(f"  è®¡ç®—æ—¶é—´: {(end_time - start_time)*1000:.2f} ms")
            print(f"  ç»“æœå½¢çŠ¶: {z.shape}")
            print(f"  ç»“æœæ ¡éªŒ: å¹³å‡å€¼={z.mean().item():.6f}")
            
            return True
        else:
            print("âœ— CUDAä¸å¯ç”¨")
            return False
            
    except ImportError:
        print("âœ— PyTorchæœªå®‰è£…ï¼Œæ— æ³•æµ‹è¯•CUDAåŠŸèƒ½")
        print("  å¯ä»¥è¿è¡Œ: pip install torch torchvision")
        return False
    except Exception as e:
        print(f"âœ— CUDAæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_tensorflow_gpu():
    """æµ‹è¯•TensorFlow GPUæ”¯æŒ"""
    try:
        import tensorflow as tf
        print(f"\nâœ“ TensorFlowç‰ˆæœ¬: {tf.__version__}")
        
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"âœ“ TensorFlowæ£€æµ‹åˆ° {len(gpus)} ä¸ªGPU:")
            for gpu in gpus:
                print(f"  - {gpu}")
                
            # ç®€å•çš„GPUè®¡ç®—æµ‹è¯•
            with tf.device('/GPU:0'):
                a = tf.random.normal([1000, 1000])
                b = tf.random.normal([1000, 1000])
                c = tf.matmul(a, b)
                
            print(f"âœ“ TensorFlow GPUè®¡ç®—æµ‹è¯•å®Œæˆ")
            print(f"  ç»“æœå½¢çŠ¶: {c.shape}")
            return True
        else:
            print("âœ— TensorFlowæœªæ£€æµ‹åˆ°GPU")
            return False
            
    except ImportError:
        print("âœ— TensorFlowæœªå®‰è£…")
        return False
    except Exception as e:
        print(f"âœ— TensorFlow GPUæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("NVIDIA GPUé©±åŠ¨æµ‹è¯•ç¨‹åº")
    print("=" * 60)
    
    # æ£€æŸ¥nvidia-smi
    nvidia_ok = check_nvidia_smi()
    
    print("\n" + "=" * 40)
    print("CUDAåŠŸèƒ½æµ‹è¯• (PyTorch)")
    print("=" * 40)
    cuda_ok = test_cuda_basic()
    
    print("\n" + "=" * 40)
    print("TensorFlow GPUæµ‹è¯•")
    print("=" * 40)
    tf_ok = test_tensorflow_gpu()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    print("=" * 60)
    print(f"nvidia-smi: {'âœ“ æ­£å¸¸' if nvidia_ok else 'âœ— å¼‚å¸¸'}")
    print(f"CUDA/PyTorch: {'âœ“ æ­£å¸¸' if cuda_ok else 'âœ— å¼‚å¸¸'}")
    print(f"TensorFlow GPU: {'âœ“ æ­£å¸¸' if tf_ok else 'âœ— å¼‚å¸¸'}")
    
    if nvidia_ok and cuda_ok:
        print("\nğŸ‰ GPUé©±åŠ¨çœ‹èµ·æ¥å·¥ä½œæ­£å¸¸ï¼")
    elif nvidia_ok:
        print("\nâš ï¸  nvidia-smiæ­£å¸¸ï¼Œä½†æ·±åº¦å­¦ä¹ æ¡†æ¶å¯èƒ½æœ‰é…ç½®é—®é¢˜")
    else:
        print("\nâŒ GPUé©±åŠ¨å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œå»ºè®®é‡æ–°æ£€æŸ¥å®‰è£…")

if __name__ == "__main__":
    main()