在很久很久以前，人工智能只是科幻小说里的概念，但如今我们已经在日常生活中广泛使用它。
机器学习通过从数据中学习模式，让计算机能够进行预测与生成。
自然语言处理让计算机可以理解、生成和编辑人类语言，这其中最具代表性的模型之一是Transformer。
训练大型语言模型通常需要大量数据和算力，但我们也可以在小数据上做微型实验来理解关键概念。
下面这段文本会被用作我们的toy数据集：它既简单又足够支持分词、训练和可视化等入门任务。
我们还会比较不同的Tokenization策略，并尝试简单的Fine-tuning来让模型更贴合特定任务。

