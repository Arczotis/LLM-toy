{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 将 llm_toy/src 加入 sys.path（稳健多候选）\n",
        "import sys as _sys\n",
        "from pathlib import Path as _Path\n",
        "def _add_src_path():\n",
        "    cands = [\n",
        "        _Path.cwd()/'llm_toy'/'src',\n",
        "        _Path.cwd()/'src',\n",
        "        _Path.cwd().parent/'llm_toy'/'src',\n",
        "        _Path.cwd().parent/'src',\n",
        "    ]\n",
        "    for base in list(_Path.cwd().parents)[:3]:\n",
        "        cands += [base/'llm_toy'/'src', base/'src']\n",
        "    for p in cands:\n",
        "        if (p/'model.py').exists() and (p/'utils.py').exists():\n",
        "            _sys.path.append(str(p.resolve()))\n",
        "            print('已添加src路径:', p.resolve())\n",
        "            return\n",
        "    print('警告：未找到 llm_toy/src，请手动添加路径或调整工作目录。')\n",
        "_add_src_path()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 08 评测指标基础：Perplexity、BLEU-1、ROUGE-1/2\n\n",
        "本Notebook提供生成式任务常见的轻量评测示例：Perplexity、BLEU-1、ROUGE-1/2。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from model import SimpleGPTModel\n",
        "from trainer import SimpleDataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perplexity 计算\n\n",
        "对一组文本，使用语言模型计算平均loss（按有效token加权），Perplexity = exp(mean_loss)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def compute_perplexity(model, tokenizer, texts, max_length=128, batch_size=4):\n",
        "    ds = SimpleDataset(texts=texts, tokenizer=tokenizer, max_length=max_length)\n",
        "    dl = DataLoader(ds, batch_size=batch_size)\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "    import torch\n",
        "    with torch.no_grad():\n",
        "        for batch in dl:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "            loss = outputs.loss\n",
        "            tokens = attention_mask.sum().item()\n",
        "            total_loss += loss.item() * tokens\n",
        "            total_tokens += tokens\n",
        "    mean_loss = total_loss / max(total_tokens, 1)\n",
        "    ppl = math.exp(mean_loss) if mean_loss < 100 else float('inf')\n",
        "    return mean_loss, ppl\n",
        "\n",
        "simple = SimpleGPTModel(model_name='gpt2')\n",
        "tok = simple.tokenizer\n",
        "lm = simple.model.to(device)\n",
        "sample_texts = [\n",
        "    '自然语言处理让计算机理解文本。',\n",
        "    'Transformer 使用 Self-Attention 建模序列。',\n",
        "    'Fine-tuning 让预训练模型适配特定任务。',\n",
        "]\n",
        "compute_perplexity(lm, tok, sample_texts, max_length=64, batch_size=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BLEU-1（简化）\n\n",
        "只考虑unigram精确率，并引入简要brevity penalty（BP）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def bleu1(hyp: str, ref: str):\n",
        "    h = hyp.split()\n",
        "    r = ref.split()\n",
        "    if len(h) == 0: return 0.0\n",
        "    ch, cr = Counter(h), Counter(r)\n",
        "    overlap = sum(min(ch[w], cr[w]) for w in ch)\n",
        "    prec = overlap / len(h)\n",
        "    c, rlen = len(h), len(r)\n",
        "    bp = math.exp(1 - rlen / c) if c < rlen and c > 0 else 1.0\n",
        "    return bp * prec\n",
        "\n",
        "bleu1('the cat is on mat', 'the cat is on the mat')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROUGE-1 / ROUGE-2（F1）\n\n",
        "基于n-gram重叠计算Precision、Recall与F1。此处实现简单版本（空格分词）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def ngrams(tokens, n):\n",
        "    return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
        "\n",
        "def rouge_n(hyp: str, ref: str, n: int = 1):\n",
        "    h_toks = hyp.split()\n",
        "    r_toks = ref.split()\n",
        "    if len(h_toks) < n or len(r_toks) < n:\n",
        "        return 0.0, 0.0, 0.0\n",
        "    from collections import Counter\n",
        "    h_ngrams = Counter(ngrams(h_toks, n))\n",
        "    r_ngrams = Counter(ngrams(r_toks, n))\n",
        "    overlap = sum(min(h_ngrams[g], r_ngrams[g]) for g in h_ngrams)\n",
        "    prec = overlap / max(sum(h_ngrams.values()), 1)\n",
        "    rec = overlap / max(sum(r_ngrams.values()), 1)\n",
        "    f1 = 2*prec*rec/(prec+rec) if (prec+rec) > 0 else 0.0\n",
        "    return prec, rec, f1\n",
        "\n",
        "rouge_n('the cat is on mat', 'the cat is on the mat', 1)\n"
      ]
    }
  ],
  "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3"}},
  "nbformat": 4,
  "nbformat_minor": 5
}
