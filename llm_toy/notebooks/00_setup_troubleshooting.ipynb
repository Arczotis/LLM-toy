{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 将 llm_toy/src 加入 sys.path（稳健多候选）\n",
        "import sys as _sys\n",
        "from pathlib import Path as _Path\n",
        "def _add_src_path():\n",
        "    cands = [\n",
        "        _Path.cwd()/'llm_toy'/'src',\n",
        "        _Path.cwd()/'src',\n",
        "        _Path.cwd().parent/'llm_toy'/'src',\n",
        "        _Path.cwd().parent/'src',\n",
        "    ]\n",
        "    for base in list(_Path.cwd().parents)[:3]:\n",
        "        cands += [base/'llm_toy'/'src', base/'src']\n",
        "    for p in cands:\n",
        "        if (p/'model.py').exists() and (p/'utils.py').exists():\n",
        "            _sys.path.append(str(p.resolve()))\n",
        "            print('已添加src路径:', p.resolve())\n",
        "            return\n",
        "    print('警告：未找到 llm_toy/src，请手动添加路径或调整工作目录。')\n",
        "_add_src_path()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup Troubleshooting Guide\n\n",
        "本Notebook用于快速排查 PyTorch/CUDA/Jupyter 环境问题，并给出可行的替代方案（CPU模式）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import sys, platform, subprocess\n",
        "import torch\n",
        "print('=== System Information ===')\n",
        "print('Python:', sys.version.split(' ')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('PyTorch:', torch.__version__)\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "print('CUDA version:', torch.version.cuda)\n",
        "print('cuDNN:', torch.backends.cudnn.version())\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 检查 NVIDIA 驱动（若无命令则忽略）\n",
        "try:\n",
        "    out = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "    if out.returncode == 0:\n",
        "        print('✅ NVIDIA driver is working')\n",
        "        print('\n'.join(out.stdout.split('\n')[:5]))\n",
        "    else:\n",
        "        print('❌ nvidia-smi failed:')\n",
        "        print(out.stderr)\n",
        "except FileNotFoundError:\n",
        "    print('❌ nvidia-smi not found - NVIDIA driver may not be installed')\n",
        "except Exception as e:\n",
        "    print('❌ Error running nvidia-smi:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# GPU 测试（可选）\n",
        "if torch.cuda.is_available():\n",
        "    print('使用GPU进行一次张量计算...')\n",
        "    x = torch.randn(4096, 4096, device='cuda')\n",
        "    y = x @ x.t()\n",
        "    print('GPU计算成功:', tuple(y.shape))\n",
        "else:\n",
        "    print('CUDA不可用，跳过GPU测试。')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# CPU 回退测试\n",
        "x = torch.randn(1000, 1000)\n",
        "y = x @ x.t()\n",
        "print('CPU计算成功:', tuple(y.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 建议\n\n",
        "- 驱动与CUDA匹配：优先使用与 PyTorch 发行版匹配的 CUDA（例如 cu118）。\n",
        "- 若驱动不匹配：先在CPU模式学习，后续再切换GPU。\n",
        "- 遇到导入报红：确保已安装依赖并重启内核，或将 llm_toy/src 标记为 Sources Root（PyCharm）。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
    "language_info": {"name": "python", "version": "3"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
